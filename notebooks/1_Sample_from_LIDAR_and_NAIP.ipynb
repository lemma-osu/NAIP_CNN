{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73c86cb-10b8-4165-b110-95a2996c796c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc03df3-b35c-4e9b-984d-0c38ee17167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 22:57:54.300109: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-03 22:57:54.420353: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-03 22:57:54.931440: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-08-03 22:57:54.931516: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-08-03 22:57:54.931524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tensorflow as tf\n",
    "from shapely.geometry import Point\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from naip_cnn.config import CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36029808-a8ea-4886-83f4-7f9879c5d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f84578-3a4c-48d4-92f4-1b6134b78f85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41c665-bb59-4b35-b934-7ebab81f6ad8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. sample_LIDAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc1d98-ed40-45a8-a3d6-e7967bd1bc89",
   "metadata": {},
   "source": [
    "function to return a feature collection and a data frame with n samples of data from the named file. Both objects contain (1) sample pixel IDs, (2) row and col IDs, (3) x and y coordinates, and (4) the lidar data value at that pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dbe88e-adc2-41b5-a6c7-9f8339b18343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_LIDAR(fname, n):\n",
    "    # Read the raster and sample from it\n",
    "    # -------------------------------------------------------------------------#\n",
    "    with rasterio.open(fname) as src:\n",
    "        lidar_rast = src.read(1, masked=True)\n",
    "        profile = src.profile\n",
    "        transform = src.transform\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        show(src, cmap=\"jet\", title=fname.split(\"/\")[-1].split(\".\")[0])\n",
    "\n",
    "        lidar_rast_flat = lidar_rast.flatten()\n",
    "        plt.hist(lidar_rast_flat, bins=100)\n",
    "        plt.title(\"Distribution of values in the map\")\n",
    "        plt.show()\n",
    "\n",
    "    # Get an index of pixels which are not masked\n",
    "    validPix = np.ma.where(np.ma.getmaskarray(lidar_rast_flat) == False)[0]\n",
    "\n",
    "    # Sample the not-masked pixel IDs\n",
    "    sample_IDs = np.random.choice(validPix, size=n, replace=False)\n",
    "\n",
    "    # Pull out the data at those sample points\n",
    "    lidar_data_sample = lidar_rast_flat[sample_IDs]\n",
    "    # -------------------------------------------------------------------------#\n",
    "\n",
    "    # Show the distribution of sample values\n",
    "    plt.hist(lidar_data_sample, bins=100)\n",
    "    plt.title(f\"Distribution of values in the sample (n = {n:,})\")\n",
    "    plt.show()\n",
    "\n",
    "    # Make sample point information\n",
    "    # -------------------------------------------------------------------------#\n",
    "    # Get row and column positions of the sample_IDs\n",
    "    row_id, col_id = np.indices(lidar_rast.shape)\n",
    "    row_id = row_id.flatten()\n",
    "    col_id = col_id.flatten()\n",
    "    row_samp = row_id[sample_IDs]\n",
    "    col_samp = col_id[sample_IDs]\n",
    "\n",
    "    # Get upper left coordinates and pixel size\n",
    "    ul_x = profile[\"transform\"][2]\n",
    "    ul_y = profile[\"transform\"][5]\n",
    "    pix_size_x = profile[\"transform\"][0]\n",
    "    pix_size_y = profile[\"transform\"][4]\n",
    "\n",
    "    # Calculate x and y coordinates\n",
    "    x_coords = [(ul_x + (col_i * pix_size_x) + pix_size_x / 2) for col_i in col_samp]\n",
    "    y_coords = [(ul_y + (row_i * pix_size_y) + pix_size_y / 2) for row_i in row_samp]\n",
    "\n",
    "    # sample_df = pd.DataFrame({'ID': sample_IDs,'row':row_samp,'col':col_samp,'x_coords':x_coords,'y_coords':y_coords, 'lidar_data': lidar_data_sample,'lidar_raster_ID': fname.split('/')[-1].split('.')[0]})\n",
    "\n",
    "    # Show the first five rows\n",
    "    # print(f'First five rows of the sample dataframe \\n{sample_df.loc[:5]}')\n",
    "    # -------------------------------------------------------------------------#\n",
    "\n",
    "    # Make geodataframe\n",
    "    # ------------------------------------------------------------------------#\n",
    "    # Create an empty GeoDataFrame to store the features\n",
    "    gdf = gpd.GeoDataFrame()\n",
    "\n",
    "    # Iterate over the centroids and create Point geometries\n",
    "    for i in range(n):\n",
    "        point_i = gpd.GeoDataFrame(geometry=[Point(x_coords[i], y_coords[i])])\n",
    "        gdf = pd.concat([gdf, point_i], ignore_index=True)\n",
    "\n",
    "    gdf.crs = CRS\n",
    "    gdf.transform = transform\n",
    "    gdf[\"pix_id\"] = sample_IDs\n",
    "    gdf[\"row\"] = row_samp\n",
    "    gdf[\"col\"] = col_samp\n",
    "    gdf[\"lidar_data\"] = lidar_data_sample\n",
    "    gdf[\"lidar_raster_ID\"] = fname.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    # Print the first five rows\n",
    "    print(f\"First five rows of the sample GeoDataFrame \\n{gdf.loc[:5]}\")\n",
    "    # ------------------------------------------------------------------------#\n",
    "\n",
    "    # Define rectangler function\n",
    "    # ------------------------------------------------------------------------#\n",
    "    def rectangler(f, buffer_size):\n",
    "        # Extract centroid coordinates from the feature\n",
    "        centroid_x, centroid_y = f.geometry.centroid.x, f.geometry.centroid.y\n",
    "\n",
    "        # Calculate rectangle coordinates\n",
    "        min_x = centroid_x - buffer_size\n",
    "        min_y = centroid_y - buffer_size\n",
    "        max_x = centroid_x + buffer_size\n",
    "        max_y = centroid_y + buffer_size\n",
    "\n",
    "        # Create the rectangle geometry using the coordinates\n",
    "        rectangle = ee.Geometry.Rectangle(\n",
    "            coords=[min_x, min_y, max_x, max_y],\n",
    "            proj=CRS,\n",
    "            geodesic=False,\n",
    "        )\n",
    "\n",
    "        # Create an Earth Engine feature\n",
    "        feature = ee.Feature(None)\n",
    "        feature = feature.setGeometry(rectangle)\n",
    "        feature = feature.set(\"pix_id\", f[\"pix_id\"])\n",
    "        feature = feature.set(\"row\", f[\"row\"])\n",
    "        feature = feature.set(\"col\", f[\"col\"])\n",
    "        feature = feature.set(\"lidar_data\", f[\"lidar_data\"])\n",
    "        feature = feature.set(\"lidar_raster_ID\", f[\"lidar_raster_ID\"])\n",
    "\n",
    "        return feature\n",
    "\n",
    "    # ------------------------------------------------------------------------#\n",
    "\n",
    "    # Make feature collection of rectangles to sample from\n",
    "    # ------------------------------------------------------------------------#\n",
    "    # Example usage\n",
    "    buffer_size = 15.0  # Buffer size in coordinate units\n",
    "\n",
    "    # Convert the GeoDataFrame to a list of features\n",
    "    features = gdf.apply(lambda row: rectangler(row, buffer_size), axis=1).tolist()\n",
    "\n",
    "    # Create an Earth Engine feature collection\n",
    "    feature_collection = ee.FeatureCollection(features)\n",
    "    # ------------------------------------------------------------------------#\n",
    "\n",
    "    # Return results\n",
    "    return feature_collection, gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ccbd1d-f00b-430c-bb32-034de072018c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2. sample_NAIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a43d7-0159-4957-8931-75a04cc8c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_NAIP(featureCollection, GDF, yr):\n",
    "    # Region to display and clip to\n",
    "    map_region = ee.Geometry.Polygon(\n",
    "        [\n",
    "            [\n",
    "                [-120.5141935519472, 43.58307281277678],\n",
    "                [-117.88022138397845, 43.58307281277678],\n",
    "                [-117.88022138397845, 44.84291584106584],\n",
    "                [-120.5141935519472, 44.84291584106584],\n",
    "            ]\n",
    "        ],\n",
    "        None,\n",
    "        False,\n",
    "    )\n",
    "\n",
    "    # Defining the LIDAR transform, subbing in NAIP pixel sizes (1 and -1) for the landsat pixel sizes (30 and -30)\n",
    "    lidar_transform_1m = list(GDF.transform[0:6])\n",
    "    lidar_transform_1m[0] = 1\n",
    "    lidar_transform_1m[4] = -1\n",
    "\n",
    "    # The NAIP data\n",
    "    image = (\n",
    "        ee.ImageCollection(\"USDA/NAIP/DOQQ\")\n",
    "        .filterDate(f\"{yr}-01-01\", f\"{yr}-12-31\")\n",
    "        .median()\n",
    "        .clip(map_region)\n",
    "        .reproject(crs=CRS, crsTransform=lidar_transform_1m)\n",
    "    )\n",
    "\n",
    "    # Define a function for reducing the NAIP data within a rectangle to a dictionary of values\n",
    "    # --------------------------------------------------------------------------------------------#\n",
    "    def reduce_region(feature):\n",
    "        reduced_data = image.reproject(CRS, lidar_transform_1m).reduceRegion(\n",
    "            reducer=ee.Reducer.toList(), geometry=feature.geometry(), scale=1\n",
    "        )\n",
    "        data_dict = ee.Dictionary(reduced_data)\n",
    "        feature = feature.set(data_dict)\n",
    "        return feature\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------#\n",
    "\n",
    "    # Bring the data local and return it\n",
    "    # --------------------------------------------------------------------------------------------#\n",
    "    reduced_data = featureCollection.map(reduce_region)\n",
    "    data_dict = reduced_data.getInfo()\n",
    "    # --------------------------------------------------------------------------------------------#\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb404d0-4c0e-4334-938e-2c3a7dd04128",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. dict_to_TFrecord "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e67a116b-9d8d-42fc-8791-ec223e855afd",
   "metadata": {},
   "source": [
    "Sends the dictionary of image and label data to a TFrecord in the format that tensorflow needs for neural network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a9f771-03c6-4d40-a173-99040970da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_TFrecord(data_dict, tfrecord_path):\n",
    "    # Get the features out of the data dictionary\n",
    "    feature_list = data_dict[\"features\"]\n",
    "\n",
    "    # Empty lists to store image data and labels in\n",
    "    dat = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop through the features and build the imagery array (X) and the data labels\n",
    "    # -------------------------------------------------------------------------------------#\n",
    "    for i in range(len(feature_list)):\n",
    "        # Pull out the properties of this feature and check which image bands are present\n",
    "        properties_i = feature_list[i][\"properties\"]\n",
    "        properties_i_keys = properties_i.keys()\n",
    "        bands = [key for key in [\"B\", \"G\", \"N\", \"R\"] if key in properties_i_keys]\n",
    "\n",
    "        # Make an image dictionary out of the present bands\n",
    "        image_dict = {band: properties_i[band] for band in bands}\n",
    "\n",
    "        # Checking to make sure there isn't empty data in here\n",
    "        if properties_i[\"B\"] is None:\n",
    "            continue\n",
    "        if properties_i[\"lidar_data\"] is None:\n",
    "            continue\n",
    "\n",
    "        # Make the image data and lable objects\n",
    "        dat.append(\n",
    "            np.array(\n",
    "                [\n",
    "                    np.array(image_dict[bands[j]]).reshape(30, 30)\n",
    "                    for j in range(0, len(image_dict))\n",
    "                ],\n",
    "                dtype=np.float32,\n",
    "            )\n",
    "        )\n",
    "        labels.append(feature_list[i][\"properties\"][\"lidar_data\"])\n",
    "\n",
    "    X = np.swapaxes(np.stack(dat), 1, 3).astype(\"float32\")\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "    # -------------------------------------------------------------------------------------#\n",
    "\n",
    "    # Define a function that creates an example object for tensorflow\n",
    "    # ----------------------------------------------------------------------------------#\n",
    "    def create_example_object_for_tf(image, label):\n",
    "        feature = {\n",
    "            \"image\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "            \"label\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[label])),\n",
    "        }\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        return example_proto.SerializeToString()\n",
    "\n",
    "    # ----------------------------------------------------------------------------------#\n",
    "\n",
    "    # Write the training data to a TFrecord\n",
    "    # ----------------------------------------------------------------------------------#\n",
    "    # Open a file connection for the TFRecordWriter\n",
    "    writer = tf.io.TFRecordWriter(tfrecord_path)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        label = labels[i].tobytes()\n",
    "        image = X[i, :, :, :].tobytes()\n",
    "\n",
    "        example_proto = create_example_object_for_tf(image, label)\n",
    "        writer.write(example_proto)\n",
    "\n",
    "    # Close the file connection!\n",
    "    writer.close()\n",
    "    # ----------------------------------------------------------------------------------#\n",
    "\n",
    "    print(\"TFrecord written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0754945a-8594-446c-a0cc-909ce32105b4",
   "metadata": {},
   "source": [
    "# Run the sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e196cdf-df4d-4e2d-ba31-61dd25f8adca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1. Set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2c17f-edf6-43dc-a9bf-55b34688bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIDAR file to sample from\n",
    "fname = \"/scratch/LIDAR/TIFS/MAL2010_FIRST_RETURNS_all_cover_above1p5_30METERS.tif\"\n",
    "\n",
    "# Number of samples to draw\n",
    "n = 5000\n",
    "\n",
    "# Year of NAIP data to pull\n",
    "naip_yr = 2011\n",
    "\n",
    "# Where to write the training data\n",
    "tfrecord_path = \"/scratch/CNN/training_data/NAIP_x_LIDAR_training_data_TEST.TFrecord\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edda2a8-a38b-404e-841c-796d4642369d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Sample from the LIDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b053e-c356-4c3a-9d2d-7074c0b0c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_FC, sampled_GDF = sample_LIDAR(fname, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bfd5c3-c09f-421b-b3b0-ce320093c867",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Sample from the NAIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4fa2b0-8c94-4589-85f4-c45ecc61e415",
   "metadata": {},
   "source": [
    "The NAIP data lives on the GEE server. The sample_NAIP function is going to be pulling data down and may take a while to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78ad89-6b62-4bcd-8393-1232fdabd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_DICT = sample_NAIP(sampled_FC, sampled_GDF, naip_yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bedbcb9-4149-4701-963c-452d049f09e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Store training data in a TFrecord "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa9301-72dd-4f4d-9b13-501b244daa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_TFrecord(sampled_DICT, tfrecord_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02274799-0ee3-4adf-a8de-8a177af3f122",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48fd100-6933-4fa0-aea2-a9f81a2ea8fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. See the NAIP imagery for the year we're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71b4b5-5e3e-4063-ad7d-cf2dfbb02d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the malheur map region\n",
    "map_region = ee.Geometry.Polygon(\n",
    "    [\n",
    "        [\n",
    "            [-120.5141935519472, 43.58307281277678],\n",
    "            [-117.88022138397845, 43.58307281277678],\n",
    "            [-117.88022138397845, 44.84291584106584],\n",
    "            [-120.5141935519472, 44.84291584106584],\n",
    "        ]\n",
    "    ],\n",
    "    None,\n",
    "    False,\n",
    ")\n",
    "\n",
    "# The NAIP data\n",
    "image = (\n",
    "    ee.ImageCollection(\"USDA/NAIP/DOQQ\")\n",
    "    .filterDate(f\"{naip_yr}-01-01\", f\"{naip_yr}-12-31\")\n",
    "    .median()\n",
    "    .clip(map_region)\n",
    ")\n",
    "\n",
    "\n",
    "# Use folium to visualize the NAIP data\n",
    "# --------------------------------------------------------------------------------------------#\n",
    "mapid = image.getMapId({\"bands\": [\"R\", \"G\", \"B\"], \"min\": 0, \"max\": 255})\n",
    "map = folium.Map(location=[44.62157, -118.98257])\n",
    "folium.TileLayer(\n",
    "    tiles=mapid[\"tile_fetcher\"].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name=\"median composite\",\n",
    ").add_to(map)\n",
    "map\n",
    "# --------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519cc3c-de87-46b9-8918-ddcb59f530f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2. See six randomly drawn sample image / label pairs from the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bac882-e02c-4aaf-af95-eadc5c3dc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_list = [24000, 130, 24020, 29870, 120, 1321]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(36, 24))\n",
    "axs_flat = axs.flatten()\n",
    "\n",
    "for i in range(0, len(i_list)):\n",
    "    ax = axs_flat[i]\n",
    "    samp = i_list[i]\n",
    "    ax.imshow(np.flip(X[samp, :, :, 0:3], 2))\n",
    "    ax.set_title(f\"canopy cover: {canCov[samp][0]} %\", fontsize=24)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

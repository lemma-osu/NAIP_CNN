{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cefa0c98-e836-47a1-a70e-0674a2c5ace0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d76e99a-9538-48af-911a-bfeff417cf86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d88c50-c08b-483f-aec9-81d4be36b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# import rasterio\n",
    "import json\n",
    "import geojson\n",
    "import glob\n",
    "import math\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv3D, Reshape, Conv2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# import tensorflow_data_validation as tfdv\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f87c18e-62e0-4731-b0bb-a4bfb2ea66d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56930dc1-94c9-449f-9c3f-5f11e0085ce8",
   "metadata": {},
   "source": [
    "### NOTE FOR ME: check on which of these actually get used in the model fitting, and which ones aren't. Currently the call to create_model_function has no parameters (uses all defaults). RECONCILE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31923c7c-dd7e-46f7-addf-b27586331a08",
   "metadata": {},
   "source": [
    "##### These are the parameters that I landed on that work well with canopy cover and the simple model architecture in the function below. These parameters are the result of a series of gridsearchCV iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d506b-c9a5-4029-a0d2-b9a5b710071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE   = 2048\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "HEIGHT = 30\n",
    "WIDTH = 30\n",
    "NUM_CHANNELS = 4\n",
    "NUM_VALIDATION_RECORDS = 5000\n",
    "BUFFER_SIZE = 10000\n",
    "tfrecord_path = \"/FILL/THIS/IN/WITH/THE/PATH/TO/YOUR/CNN/training_data/NAIP_x_LIDAR_training_30k_v4.TFrecord\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b67b7e-7f26-42e4-8f46-67ee603a7a8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Some GPU management / checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3282b24-f58b-4c5e-a7fa-e20aa03e57f1",
   "metadata": {},
   "source": [
    "##### See what's available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb8351-b637-4a1f-a243-422bd1692369",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79432038-69a2-453b-bd17-469b721a175c",
   "metadata": {},
   "source": [
    "##### If you run into trouble where your GPU-utilizing code won't run because the GPU RAM is allocated (even though you're pretty sure it should be free), try tf.keras.backend.clear_session(), which sometimes helps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f4810-7a90-4269-a623-4986142dad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79886d32-f97a-431c-aa10-2d420bc8e708",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720af39-d233-4bcd-8a07-d05613f5b8b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. parse_training_tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33315e48-8c58-40d3-8215-88a326febd50",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### uses an example of what each training pair (image + label) should look like to unpack the training pairs from the training dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9107164-b38b-4279-b054-511a9320498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the training TFRecord data\n",
    "def parse_training_tfrecord(example_proto):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    image = tf.io.decode_raw(features[\"image\"], tf.float32)\n",
    "    label = tf.io.decode_raw(features[\"label\"], tf.float32)\n",
    "    image = tf.reshape(image, [HEIGHT, WIDTH, NUM_CHANNELS])\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d064988-9ea0-4183-817d-34cab63bc3ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2. create_model_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce8aa79-f8db-4520-83e6-698f9a655439",
   "metadata": {},
   "source": [
    "##### contains the method for building the neural network. This particular network will have a 3D convolution layer (the filters have dimensions of kernel_dim x kernel_dim x number of bands), a flatten, and three dense layers (with dropouts between the layers). This is a simple formulation of a convolutional neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f5c0e-f6fe-46a8-90d8-6e937fbe4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct the CNN\n",
    "def create_model_function(\n",
    "    init_mode=\"uniform\",\n",
    "    optimiz0r=\"adam\",\n",
    "    batch_size=1024,\n",
    "    kernel_dim=5,\n",
    "    filter_no=32,\n",
    "    Dense1_no=256,\n",
    "    Dense2_no=32,\n",
    "    learn_rate=0.001,\n",
    "    momentum=0.2,\n",
    "):\n",
    "    kernel_size = (kernel_dim, kernel_dim, NUM_CHANNELS)\n",
    "\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            Conv3D(\n",
    "                filters=filter_no,\n",
    "                kernel_size=kernel_size,\n",
    "                input_shape=(HEIGHT, WIDTH, NUM_CHANNELS, 1),\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "                use_bias=True,\n",
    "            ),\n",
    "            Flatten(),\n",
    "            Dense(Dense1_no, activation=\"relu\"),\n",
    "            Dropout(0.4),\n",
    "            Dense(Dense2_no, activation=\"relu\"),\n",
    "            Dropout(0.4),\n",
    "            Dense(units=1, activation=\"linear\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if optimiz0r == \"adam\":\n",
    "        optimizer = Adam(learning_rate=learn_rate)\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27ceef-9fea-42e9-9673-93236f5f7803",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. parse_imagery_tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d3d58-33d8-4d6b-b046-470d90863416",
   "metadata": {},
   "source": [
    "##### This function is used when it's time to make predictions (maps). It is used to parse the series of .tfrecord files that contain the image data from our area of interest. Data will be streamed from those .tfrecord files, fed into the model, and in the end we will have a number of predictions that matches the number of 30m pixels contained in our area of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce851a32-cf66-40d6-bf58-29f78b78c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map over the NAIP data (in TFRecords) to get it in the format that our model takes\n",
    "def parse_imagery_tfrecord(serialized_example):\n",
    "    feature = {\n",
    "        \"B\": tf.io.FixedLenFeature([900], tf.float32),\n",
    "        \"G\": tf.io.FixedLenFeature([900], tf.float32),\n",
    "        \"N\": tf.io.FixedLenFeature([900], tf.float32),\n",
    "        \"R\": tf.io.FixedLenFeature([900], tf.float32),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature)\n",
    "\n",
    "    # Convert the input features to the format expected by the model\n",
    "    B = tf.reshape(example[\"B\"], [30, 30])\n",
    "    G = tf.reshape(example[\"G\"], [30, 30])\n",
    "    R = tf.reshape(example[\"R\"], [30, 30])\n",
    "    N = tf.reshape(example[\"N\"], [30, 30])\n",
    "    image = tf.stack([B, G, R, N], axis=-1)\n",
    "\n",
    "    return tf.expand_dims(image, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942c33c-6052-408a-8e6e-d353b13484b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read in the training data. Create training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a689c-6cff-4e98-b8f5-060d069421e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection object\n",
    "full_dataset_con = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "# Map the parsing function over the connection object\n",
    "full_dataset = full_dataset_con.map(\n",
    "    parse_training_tfrecord, num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "# Split the training data in train and validation sets\n",
    "validation_dataset = full_dataset.take(NUM_VALIDATION_RECORDS)\n",
    "train_dataset = full_dataset.skip(NUM_VALIDATION_RECORDS)\n",
    "\n",
    "\n",
    "# function to augment the images\n",
    "def augment(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "# apply data augmentation to the images in the dataset\n",
    "train_dataset = train_dataset.map(lambda x, y: (augment(x), y))\n",
    "\n",
    "# Do some other mysterious things to the data\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.repeat(NUM_EPOCHS)\n",
    "\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680991a6-326b-4771-99eb-bcacbc7d8e6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training pt. 1: Run a gridsearchCV on the model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b6bb04-acf0-4546-ba09-2715c990eaa3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### CAUTION: This code fits here in the process, but is ***not*** written for the most current data format. I ran gridsearchCV on training data stored in a different format (not in .tfrecords, and therefore parsed differently). All of the code in the cell below ought to apply / be valid, but will need to be changed slightly to accomodate the .tfrecord flow.     \n",
    "\n",
    "##### SEE NOTES next to the lists that go into the grid to see what I came up w/ for model performance scores while adjusting the parameters (partway by hand). \n",
    "\n",
    "##### Why did I do the gridesearchCV partway by hand? I did multiple small, successive searches (as opposed to setting up one big ol' grid search and letting it rip) because of a memory leak in the gridsearchCV process. I could watch my system memory usage creep up and up over the hours, and by hour 7 or so the system memory would be exhaused and the process would crash. So, I had to break the job down in to smaller searches.\n",
    "\n",
    "##### Has tensorflow fixed the memory leak bug? Will this bug not be an issue on a windows system (as opposed to Linux)? Hard to tell, but worth a shot trying it out! Just keep an eye on the process. \n",
    "\n",
    "#####  The general wisdom I gleaned from various sources was to test the optimizer and learning rate early on, then start fiddling with the stuff pertaining to the model architecture ( kernel size and number of filters on the Conv3D, number of nodes on the dense layers, etc....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f24b331-5f62-4532-bb03-ab4fd03e02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_2(\n",
    "    init_mode=\"uniform\",\n",
    "    optimiz0r=\"adam\",\n",
    "    batch_size=10,\n",
    "    kernel_dim=2,\n",
    "    filter_no=16,\n",
    "    Dense1_no=128,\n",
    "    Dense2_no=64,\n",
    "    learn_rate=0.01,\n",
    "    momentum=0.2,\n",
    "):\n",
    "    kernel_size = (kernel_dim, kernel_dim, 4)\n",
    "\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            Conv3D(\n",
    "                filters=filter_no,\n",
    "                kernel_size=kernel_size,\n",
    "                input_shape=(30, 30, 4, 1),\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                use_bias=True,\n",
    "            ),\n",
    "            Flatten(),\n",
    "            Dense(Dense1_no, activation=\"relu\"),\n",
    "            Dropout(0.4),\n",
    "            Dense(Dense2_no, activation=\"relu\"),\n",
    "            Dropout(0.4),\n",
    "            Dense(units=1, activation=\"linear\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if optimiz0r == \"adam\":\n",
    "        optimizer = Adam(learning_rate=learn_rate)\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Random seed (?)\n",
    "np.random.seed(seed=42)\n",
    "\n",
    "# create the sklearn model for the network\n",
    "model_init = KerasRegressor(\n",
    "    model=create_model_2,\n",
    "    epochs=20,\n",
    "    verbose=2,\n",
    "    kernel_dim=2,\n",
    "    filter_no=16,\n",
    "    Dense1_no=32,\n",
    "    Dense2_no=16,\n",
    "    learn_rate=0.01,\n",
    "    momentum=0.2,\n",
    ")\n",
    "\n",
    "# we choose the initializers that came at the top in our previous cross-validation!!\n",
    "# init_list = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "# grid search for initializer, batch size and number of epochs\n",
    "# param_grid = dict(epochs=epochs, batch_size=batches, init=init_mode)\n",
    "batch_list = [1024]  # Batch size of 1000 had the best R2 of 0.57 when epochs was 20\n",
    "epoch_list = [20]  # Best R2 of 0.57 when epochs was 20 (tested [20,30,40,50,100,200]).\n",
    "kernel_dim_list = [\n",
    "    5\n",
    "]  # Best R2 of 0.58 when kernel_dim was 5 (tested [2,3,4,5,6,7,8,9,10]).\n",
    "filter_list = [\n",
    "    32\n",
    "]  # Best R2 of 0.5755 at 64 filters, but 32 filters not too far behind (0.5721) and much faster (tested [16,32,64,128,256]).\n",
    "Dense1_list = [256]\n",
    "Dense2_list = [32]\n",
    "learn_list = [0.0001, 0.001, 0.002, 0.005, 0.01, 0.02]\n",
    "momentum_list = [0.2]\n",
    "param_grid = dict(\n",
    "    epochs=epoch_list,\n",
    "    batch_size=batch_list,\n",
    "    kernel_dim=kernel_dim_list,\n",
    "    filter_no=filter_list,\n",
    "    Dense1_no=Dense1_list,\n",
    "    Dense2_no=Dense2_list,\n",
    "    learn_rate=learn_list,\n",
    "    momentum=momentum_list,\n",
    ")\n",
    "grid = GridSearchCV(\n",
    "    estimator=model_init, param_grid=param_grid, cv=2, error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# Print the keys of the estimator object \"grid\", to see what all is involved\n",
    "# print(grid.get_params().keys())\n",
    "\n",
    "grid_result = grid.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688a2c4-d14c-4c7c-8c4a-ba263ef7b40b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training pt. 2: Fit the model with the selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1ec66-a4f5-41e6-82cd-1b7646272c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = create_model_function()\n",
    "model.compile(\n",
    "    loss=\"mean_squared_error\", optimizer=\"adam\", metrics=\"RootMeanSquaredError\"\n",
    ")\n",
    "history = model.fit(\n",
    "    train_dataset, verbose=1, validation_data=validation_dataset, epochs=NUM_EPOCHS\n",
    ")\n",
    "# history = model.fit(train_dataset,verbose=1,validation_data = validation_dataset, steps_per_epoch = 29,epochs = NUM_EPOCHS)\n",
    "\n",
    "# With batch size 1024, we got an r squared of 0.42\n",
    "# With batch size 2048, we got an r squared of 0.49\n",
    "# With batch size 1500, we got an r squared of\n",
    "# Then, expanding validation dataset to 5000.....maybe a little better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01baf55-a2d0-4e2f-9df5-1202ab29eac9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbef78b-7a2c-4a0d-aa5f-6dc26fddbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('/md1/data/NAIP/trained_models/CNN_canCov_v1.1', save_format='tf')\n",
    "model.save(\n",
    "    \"/FILL/THIS/IN/WITH/THE/PATH/TO/YOUR/trained_models/CNN_canCov_v1.1_batch64\",\n",
    "    save_format=\"tf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac405f2-a86b-468a-9109-1841f832286c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ed5bd-8aeb-4cc5-9e87-a99aeb37a808",
   "metadata": {},
   "source": [
    "### Use the validation data to test the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68391fbf-4177-493a-a25c-0e9822dc3918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predicted_Labels\n",
    "predictions = model.predict(validation_dataset)\n",
    "# print(f'The first ten predicted values {predictions[0:10]}')\n",
    "\n",
    "# Make val_labels\n",
    "val_labels = []\n",
    "for _, label in validation_dataset:\n",
    "    val_labels.append(label.numpy())\n",
    "val_labels = np.concatenate(val_labels)\n",
    "# print(f'The first ten labels in the validation dataset {val_labels[0:10]}')\n",
    "\n",
    "# Compute R squared\n",
    "r_squared = r2_score(val_labels, predictions)\n",
    "\n",
    "# Reformating predictions (x_forfit) and val_labels (y_forfit) for what LinearRegression wants\n",
    "x_forfit = np.array(predictions).reshape((-1, 1))\n",
    "y_forfit = val_labels\n",
    "\n",
    "# Do the regression\n",
    "lm = LinearRegression().fit(X=x_forfit, y=y_forfit)\n",
    "r_sq = lm.score(x_forfit, y_forfit)\n",
    "m = lm.coef_[0]\n",
    "b = lm.intercept_\n",
    "\n",
    "# Print regression info\n",
    "print(f\"R squared value: {r_sq: .3f}\")\n",
    "print(f\"intercept: {b[0]: .2f}\")\n",
    "print(f\"slope: {m[0]: .2f}\")\n",
    "\n",
    "# Compute RMSE and print it\n",
    "RMSE = math.sqrt(mean_squared_error(val_labels, predictions))\n",
    "print(f\"RMSE for the predicted canopy height: {RMSE: .2f}\")\n",
    "\n",
    "# Heatmap scatterplot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.hexbin(x=predictions, y=val_labels, gridsize=20)\n",
    "plt.plot(x_forfit, m * x_forfit + b, color=\"red\")\n",
    "plt.title(f\"Canopy Cover - Rsquared: {r_sq: .3f}, RMSE {RMSE: .2f}\", fontsize=20)\n",
    "plt.xlim([5, 70])\n",
    "plt.ylim([5, 70])\n",
    "plt.plot([5, 70], [5, 70], \"--\", color=\"black\")\n",
    "plt.colorbar()\n",
    "plt.ylabel(\"Actual Cover (%)\", fontsize=20)\n",
    "plt.xlabel(\"Predicted cover (%)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d7d248-c8ee-45bc-86a6-b31f44b508e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optional: make plots to do a sanity check on the data. Clear session afterwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8acdb-e10f-45c5-8228-fc6064764d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = []\n",
    "# image_list = []\n",
    "\n",
    "# for image, label in full_dataset:\n",
    "#     labels.append(label.numpy())\n",
    "#     image_list.append(image.numpy())\n",
    "\n",
    "# labels = np.concatenate(labels)\n",
    "# X = np.array(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6c177-2a72-46b5-996e-2c166d4e2b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #i_list = [1414,20000,24020,0,500,1500,]\n",
    "# i_list = [24000,130,24020,29870,120,1321]\n",
    "\n",
    "# fig, axs = plt.subplots(nrows = 2, ncols = 3, figsize = (36,24))\n",
    "# axs_flat = axs.flatten()\n",
    "\n",
    "# for i in range(0,len(i_list)):\n",
    "#     ax = axs_flat[i]\n",
    "#     samp = i_list[i]\n",
    "#     ax.imshow(np.flip(X[samp,:,:,0:3], 2))\n",
    "#     ax.set_title(f'canopy cover: {labels[samp]} %', fontsize = 24)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82843f75-f74e-407f-94d2-a25699562d44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Make a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c5382-1e4e-4dff-8f17-6b2c65eca5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "# mixer         = json.load(open('/scratch/CNN/image_prediction/Malheur_small_bbox_2011-mixer.json'))\n",
    "file_patterns = sorted(\n",
    "    glob.glob(\n",
    "        \"/FILL/THIS/IN/WITH/THE/PATH/TO/YOUR/imagery_for_prediction/Malheur_small_bbox_2011_nativeProj-0000*.tfrecord\"\n",
    "    )\n",
    ")\n",
    "dataset = tf.data.TFRecordDataset(file_patterns)\n",
    "dataset = dataset.map(parse_imagery_tfrecord).batch(batch_size)\n",
    "predictions = model.predict(dataset)\n",
    "# dataset      = tf.data.TFRecordDataset(mixer.tfrecord_file_paths())\n",
    "# dataset      = dataset.map(map_func=parse_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# dataset      = dataset.batch(batch_size)\n",
    "# predictions = model.predict(dataset)\n",
    "np.savetxt(\n",
    "    \"/FILL/THIS/IN/WITH/THE/PATH/TO/YOUR/predicted_vectors/Malheur_small_bbox_2011.csv\",\n",
    "    predictions,\n",
    "    delimiter=\",\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fd59d-9642-4077-a147-ae56be107254",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(predictions_smallest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e38f1-2453-429d-898a-896d85d05500",
   "metadata": {},
   "source": [
    "#### Write the predictions out as a GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e08af-19a6-44e5-aa9e-6dab0f965eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the metadata\n",
    "import json\n",
    "\n",
    "with open(\n",
    "    \"/FILL/THIS/IN/WITH/THE/PATH/TO/YOUR/imagery_for_prediction/Malheur_small_bbox_2011_nativeProj-mixer.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "ncol = meta[\"patchesPerRow\"]\n",
    "nrow = meta[\"totalPatches\"] / ncol\n",
    "affine = meta[\"projection\"][\"affine\"][\"doubleMatrix\"]\n",
    "affine[0] = affine[0] * 30\n",
    "affine[4] = affine[4] * 30\n",
    "crs = meta[\"projection\"][\"crs\"]\n",
    "print(meta)\n",
    "\n",
    "pred_raster = predictions.reshape(int(nrow), int(ncol))\n",
    "\n",
    "profile = dict(\n",
    "    dtype=rasterio.float32,\n",
    "    count=1,\n",
    "    compress=\"lzw\",\n",
    "    height=nrow,\n",
    "    width=ncol,\n",
    "    driver=\"GTiff\",\n",
    "    crs=crs,\n",
    "    transform=affine,\n",
    ")\n",
    "\n",
    "with rasterio.open(\n",
    "    \"/FILL/THIS/IN/WITH/THE/PATH/TO/YOUR/CNN/predicted_vectors/test.tif\", \"w\", **profile\n",
    ") as fh:\n",
    "    fh.write(pred_raster, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d75e06-68d0-4085-ad94-1ab06186124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(pred_raster)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

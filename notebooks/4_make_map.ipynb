{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3207f0af-3c2f-45e5-8ca5-16b949a06e72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Setup\n",
    "\n",
    "Import the libraries, set up the GLOBAL variables, and run the google authentications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95192ce0-aa1e-477a-8323-0eddb63d3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import rasterio\n",
    "import glob\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import folium\n",
    "import ee\n",
    "from pprint import pprint\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "\n",
    "# Specify the key for accessing the google cloud project\n",
    "KEY_PATH = \"/home/climber/.keys/ee-maptheforests-access-key.json\"\n",
    "\n",
    "# Our bucket\n",
    "BUCKET_NAME = \"naip_structure\"\n",
    "\n",
    "# Set the directories where we will want to grab TFrecords from on gcloud\n",
    "GCLOUD_NAIP_DIR = \"naip_Malheur_TFrecords/\"\n",
    "\n",
    "# Where to put them on Treenet\n",
    "TREENET_NAIP_DIR = \"/scratch/NAIP_data/malheur/2011/\"\n",
    "\n",
    "# Name of the output raster name\n",
    "TIF_NAME = \"Malheur_bbox_predicted_canCov_v1.tif\"\n",
    "\n",
    "# Assets folder in GEE\n",
    "GEE_USER_FOLDER = \"users/forestMapper\"\n",
    "\n",
    "# Input bands to the model\n",
    "BANDS = [\"B\", \"G\", \"R\", \"N\"]\n",
    "\n",
    "# The shape of patches expected by the model\n",
    "KERNEL_SHAPE = [30, 30]\n",
    "\n",
    "# Speicfy where the model file is on the different platforms\n",
    "MODEL_ON_GCLOUD = \"gs://\" + BUCKET_NAME + \"/CNN_models/CNN_canCov_v1\"\n",
    "MODEL_ON_TREENET = \"/scratch/CNN/models/canCov_model_2011_v1/\"\n",
    "\n",
    "# Authenticate and intialize earth engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# The bounding box of the area we'd like to map over\n",
    "MAP_REGION = ee.Geometry.Polygon(\n",
    "    [\n",
    "        [\n",
    "            [-119.37239004502233, 44.48079613290612],\n",
    "            [-118.57725454697545, 44.48079613290612],\n",
    "            [-118.57725454697545, 44.81785572318615],\n",
    "            [-119.37239004502233, 44.81785572318615],\n",
    "        ]\n",
    "    ],\n",
    "    None,\n",
    "    False,\n",
    ")\n",
    "\n",
    "# print(f'Available hardware: {tf.config.list_physical_devices()}')\n",
    "# print(f'Tensorflow version {tf.__version__}')\n",
    "# print(f'folium version {folium.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0143e2-574b-4a96-af5e-213a84db4bdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2.  Check out the imagery for MAP_REGION and year of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ecd989-3ca8-4b81-aafb-740fdbaa8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NAIP image collection\n",
    "naip = ee.ImageCollection(\"USDA/NAIP/DOQQ\")\n",
    "\n",
    "# The image input data is a cloud-masked median composite.\n",
    "image = naip.filterDate(\"2011-01-01\", \"2011-12-31\").median().clip(MAP_REGION)\n",
    "\n",
    "# Use folium to visualize the imagery.\n",
    "mapid = image.getMapId({\"bands\": [\"R\", \"G\", \"B\"], \"min\": 0, \"max\": 255})\n",
    "map = folium.Map(location=[44.62157, -118.98257])\n",
    "folium.TileLayer(\n",
    "    tiles=mapid[\"tile_fetcher\"].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name=\"median composite\",\n",
    ").add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e6ec2-26c5-4472-a9d2-8752300f8e08",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3. Running the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c02a32-1d9a-40dc-87b6-6093a48282e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the default graph and free up GPU memory\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccd3ff-5079-4eae-b201-0ac42db892ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with tf.device('/cpu:0'):\n",
    "# m = tf.keras.models.load_model(MODEL_ON_TREENET)\n",
    "m = tf.keras.models.load_model(\"/md1/data/NAIP/trained_models/CNN_canCov_v1.1/\")\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ae466-894a-44d2-8ece-9a36335697ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = os.listdir(TREENET_NAIP_DIR)\n",
    "imageFilesList = sorted(\n",
    "    [f\"{TREENET_NAIP_DIR}{s}\" for s in flist if \".tfrecord.gz\" in s]\n",
    ")\n",
    "jsonFile = [s for s in flist if \"mixer.json\" in s][0]\n",
    "\n",
    "with open(f\"{TREENET_NAIP_DIR}{jsonFile}\", \"r\") as f:\n",
    "    mixer = json.load(f)\n",
    "pprint(mixer)\n",
    "\n",
    "# pprint(mixer)\n",
    "patches = mixer[\"totalPatches\"]\n",
    "\n",
    "\n",
    "# Function to map over the NAIP data (in TFRecords) to get it in the format that our model takes\n",
    "def parse_imagery_tfrecord(serialized_example):\n",
    "    feature = {\n",
    "        \"B\": tf.io.FixedLenFeature([900], tf.float32),\n",
    "        \"G\": tf.io.FixedLenFeature([900], tf.float32),\n",
    "        \"N\": tf.io.FixedLenFeature([900], tf.float32),\n",
    "        \"R\": tf.io.FixedLenFeature([900], tf.float32),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature)\n",
    "\n",
    "    # Convert the input features to the format expected by the model\n",
    "    B = tf.reshape(example[\"B\"] / 255, [30, 30])\n",
    "    G = tf.reshape(example[\"G\"] / 255, [30, 30])\n",
    "    R = tf.reshape(example[\"R\"] / 255, [30, 30])\n",
    "    N = tf.reshape(example[\"N\"] / 255, [30, 30])\n",
    "    image = tf.stack([B, G, R, N], axis=-1)\n",
    "\n",
    "    return tf.expand_dims(image, axis=-1)\n",
    "\n",
    "\n",
    "# Create a dataset from the TFRecord file(s) in Cloud Storage.\n",
    "imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type=\"GZIP\")\n",
    "imageDataset = imageDataset.map(parse_imagery_tfrecord).batch(500)\n",
    "\n",
    "print(\"Running predictions...\")\n",
    "predictions = m.predict(imageDataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7b9eb-abf2-44db-bfdd-31f17b80df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03e988-9771-444b-88eb-aac167ee6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD: used to be a function called doPrediction()\n",
    "# predictions = doPrediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31a33c-6d10-4cc8-a7ee-4491dc87a393",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 4. Write the predictions as a .tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf45d6-2c41-4e52-907c-94122ee3b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeRaster(predictions, GDRIVE_FOLDER, TIF_NAME):\n",
    "    # Find the mixer file\n",
    "    flist = !gsutil ls 'gs://'{BUCKET}'/'{TF_FOLDER}\n",
    "    jsonFile = [s for s in flist if \"mixer.json\" in s][0]\n",
    "\n",
    "    # Load the contents of the mixer file to a JSON object.\n",
    "    jsonText = !gsutil cat {jsonFile}\n",
    "\n",
    "    # Get a single string w/ newlines from the IPython.utils.text.SList\n",
    "    mixer = json.loads(jsonText.nlstr)\n",
    "\n",
    "    ncol = mixer[\"patchesPerRow\"]\n",
    "    nrow = mixer[\"totalPatches\"] / ncol\n",
    "    affine = mixer[\"projection\"][\"affine\"][\"doubleMatrix\"]\n",
    "    affine[0] = affine[0] * 30\n",
    "    affine[4] = affine[4] * 30\n",
    "    crs = mixer[\"projection\"][\"crs\"]\n",
    "\n",
    "    pred_raster = predictions.reshape(int(nrow), int(ncol))\n",
    "\n",
    "    profile = dict(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1,\n",
    "        compress=\"lzw\",\n",
    "        height=nrow,\n",
    "        width=ncol,\n",
    "        driver=\"GTiff\",\n",
    "        crs=crs,\n",
    "        transform=affine,\n",
    "    )\n",
    "\n",
    "    # with rasterio.open('gs://naip_structure/predicted_canCov/test.tif', 'w',**profile) as fh:\n",
    "    with rasterio.open(\n",
    "        f\"/gdrive/My Drive/{GDRIVE_FOLDER}/{TIF_NAME}\", \"w\", **profile\n",
    "    ) as fh:\n",
    "        fh.write(pred_raster, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fd07c-c91e-468e-9f98-b9557f0e25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeRaster(predictions, GDRIVE_FOLDER, TIF_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
